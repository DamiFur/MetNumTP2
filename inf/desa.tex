\section{Desarrollo}

\subsection{M\'etodos para la experimentaci\'on}

Para poder predecir qu\'e' d\'igito representa una imagen, utilizaremos los siguientes tres m\'etodos que fueron vistos en clase. Para cada uno, tendremos como entrada la matriz de train, test y ciertos parametros de configuraci\'on utilizados por cada uno.

\subsubsection{kNN}

El m\'etodo de kNN se basa en tener una lista de vectores, cada uno representando una imagen de train de la cu\'al sabemos a qu\'e d\'igito corresponde. Luego, para cada imagen de test, la convertiremos en un vector y compararemos contra la lista de vectores que ya tenemos y nos quedaremos con los k de menor distancia cuadrada. Estos k vectores mas cercanos luego ''votar\'an'' seg\'un el d\'igito que representan y nos quedaremos con el mas votado.\\

Utilizamos para medir la distancia el m\'odulo de la diferencia entre dos puntos al cuadrado en lugar de usar simplemente el m\'odulo para evitar introducir un error numérico al calcular la raíz cuadrada. Como nuestro objetivo al calcular la distancia es simplemente encontrar un orden relativo para poder seleccionar los k puntos (imágenes) de nuestra base de train que serán habilitadas para votar la clase de pertenencia de la imágen que estamos analizando, el módulo al cuadrado nos otorga un orden equivalente al del módulo e incluso le agrega mayor precisión al evitar utilizar la función ra\'iz. Esto sucede porque para cualquier $a$, $b$ $\in$ $\mathds{R}$ vale $|a| < |b|$ $\Leftrightarrow$ $a_{2} < b_{2}$. Como consecuencia secundaria, además, utilizar esta métrica también reduce el tiempo de cómputo que agrega el cálculo inecesario de la ra\'iz.\\

Para poder obtener los k de menor distintancia a nuestro vector de una manera eficiente, utilizamos un set en donde guardamos cada distancia entre dos im\'agenes y cuando el set supera el tama\~no k, eliminamos su \'ultimo elemento. Recordemos que el set ordena sus elementos de menor a mayor y el ''\'ultimo elemento'' representa el mas grande, lo que nos asegura que de esta manera vamos a obtener los k de menor distancia. Como decisión de implementación, en caso de haber dos vectores de distancias iguales, nuestro algoritmo va a desempatar por el menor d\'igito. Decidimos esta manera de desempatar porque es determin\'istica y simple.\\
Luego, a la hora de votar, puede haber empates y en ese caso decidimos quedarnos con el que tenga el voto mas cercano. Es decir, volvemos a ver los vectores que votaron en orden de menor a mayor distancia y cuando encontramos uno que voto por alguno de los empatados, usamos ese voto para desempetar. Puede pasar que existan dos vectores de igual distancia y en ese caso decidimos que nuestro algoritmo haga ganar el de menor d\'igito.

\subsubsection{PCA}

El método PCA no es un método para determinar una clase de pertenencia para una imagen sin clasificar en sí sino más bien una técnica para comprimir la información de un vector de una dimension $n$ a una dimension $m$ de menor tamaño. Pensando cada vector-imagen como un punto de dimensi\'on $n$ (donde $n$ es el tamaño del vector), PCA calcula una matriz de covarianza entre los distintos puntos. La covarianza aporta una manera de medir la 'similaridad' en cuanto a la forma de variar entre uno y otro punto de la dimensión $n$. Una covarianza alta puede interpretarse como una dependencia o relación entre dos valores y por lo tanto puede pensarse como un dato redundante. PCA busca disminuir esta redundancia mediante un cambio de base que disminuya la covarianza maximizando la varianza (la diferencia entre dos puntos). La matriz de covarianza calculada a partir de nuestra matriz de imágenes (interpretados como puntos en el plano) realiza una transformación lineal que se interpreta geométricamente como un corrimiento de los ejes que 'centra' nuestros datos, como puede verse en la figura \ref.
Para esto, genera una nueva matriz compuesta de los autovectores de la matriz de covarianza, los cuales calcula mediante el método iterativo de la potencia. 

\subsubsection{PLS-DA}

\subsection{Detalles generales de la implementaci\'on}

\subsubsection{Inicializaci\'on}

En el main de nuestro programa, leemos la entrada seg\'un lo especificado por el enunciado y el formato de archivos del TP. La funci\'on trainMatrix se encarga de levantar en memoria y llenar una matriz de doubles con la informaci\'on de train en donde cada fila representa una imagen y las columnas sus distintos pixeles. Adem\'as, nos sera de utilidad una funci\'on llamada filtrarPartition para poder filtrar nuestra partici\'on, algo que utilizaremos a lo largo de nuestro programa para poder analizar nuestro algoritmo en base a la informaci\'on de training.

\subsection{M\'etricas para los experimentos}

El trabajo pr\'actico nos propone elegir dos m\'etricas para realizar los experimentos y luego poder comparar cualitativamente cada uno. De las distintas m\'etricas, decidimos elegir ''Precision'', ''Recall'' y adem\'as ''F1-Score'' ya que es muy simple de usar teniendo las anteriores dos m\'etricas implementadas.

\subsubsection{Precision}

Sea $i$ una clase, en este caso, un d\'igito determinado. Llamaremos $tp_i$ a la cantidad de verdaderos positivos, es decir, d\'igitos de test que nuestro algoritmo dice que su d\'igito es $i$ y efectivamente ese es el d\'igito. Llamemos $fp+i$ a la cantidad de falsos positivos, es decir, \'igitos de test que nuestro algoritmo dice que su d\'igito es $i$, pero en realidad es otro d\'igito. La precision, se calcula para una cierta clase $i$ como $\frac{tp_i}{tp_i+fp_i}$. Si queremos la precision de un conjunto de clases, debemos calcular el promedio entre la precision de cada una. En nuestro caso, eso ser\'ia hacer $\frac{\sum_{i=0}^{i<10} \frac{tp_i}{tp_i+fp_i}}{10} $\\

\subsubsection{Recall}

El m\'etodo es similar a Precision, pero utilizaremos $fn_i$ como los falsos negativos de una clase $i$, es decir, d\'igitos que nuestros algoritmo dice que no pertenecen a la clase $i$ pero en realidad si pertenecen. De esta manera, Recall se define como $\frac{tp_i}{tp_i+fn_i}$ y al igual que el m\'etodo anterior, el recall de todas las clases es el promedio de cada una de ellas.

\subsubsection{F1-Score}

Este m\'etodo utiliza Precision y Recall, que tienen calidades distintas para cada clase, para medir un cierto compromiso entre los dos resultados. En concreto, F1-Score se define como $\frac{2 * precision * recall}{precision + recall}$.

\subsection{Train provisto por la c\'atedra}

Calculamos cu\'antas veces aparec\'ia cada d\'igito en los tests provistos por la c\'atedra utilizando un script hecho en python contando los labels. Nos parec\'ia interesante para la discusi\'on esta informaci\'on y nos puede llegar a ser \'util. El resultado que obtuvimos fue:

\begin{table}[H]
\centering
\begin{tabular}{| l | c | c | c | c | c | c | c | c | c | c |}
\hline
& 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\hline
Aparici\'on & 4132 & 4684 & 4177 & 4351 & 4072 & 3795 & 4137 & 4401 & 4063 & 4188\\

\hline
\end{tabular}
\caption{Cantidad de casos de train por d\'igito}
\end{table}